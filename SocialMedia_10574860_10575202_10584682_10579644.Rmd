---
title: "Comparison Between the Facebook Pages for Different Platforms"
author: "Jack Brewer, Aden Webb, Avebry Haughton-Vowles, Kacper Mazur"
date: "12 February 2018"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)

#---Packages---
library(Rfacebook)
citation("Rfacebook")
library(stringr) # Character manipulation
library(dplyr) # Data wrangling
library(ggplot2) # Graphics
library(tidyr) # Turning wide data into long data
library(tm) # Text mining
library(wordcloud) # Word cloud
library(network) # Network diagram
library(curl) # Needed to get information about me and my friends
library(httr) # Needed to get information about me and my friends
library(lubridate) # For date manipulation
library(scales) # To format axes
library(wordcloud2)

#---Functions---

format.facebook.date <- function(datestring) {
  date <- as.POSIXct(datestring, 
                     format = "%Y-%m-%dT%H:%M:%S+0000", 
                     tz = "GMT")
  date
}

remove_http_www <- function(some_txt){
    #
    some_txt <- str_replace_all(some_txt, 
                                "http\\:\\/\\/[A-Za-z0-9\\.\\/\\?\\=]+(\\s?)", "")
    #
    some_txt <- str_replace_all(some_txt, 
                                "https\\:\\/\\/[A-Za-z0-9\\.\\/\\?\\=]+(\\s?)", "")
    # 
    some_txt <- str_replace_all(some_txt, 
                                "www\\.[A-Za-z0-9\\.\\/\\?\\=]+(\\s?)", "")
    #
    return(some_txt)
}

remove.numbers <- function(some_txt){
    # Remove separate numbers
    some_txt <- str_replace_all(some_txt, "\\s\\d+", " ") #
    #
    # Remove numbers in brackets
    some_txt <- str_replace_all(some_txt, "\\(\\d+\\)", "") 
    #
    # Remove numbers at the beginning
    some_txt <- str_replace_all(some_txt, "^\\d+\\s", "")
    #
    # Remove numbers at the end
    some_txt <- str_replace_all(some_txt, "\\s\\d+$", "")
    #
    some_txt
}

remove.spaces <- function(some_txt){
    # If more than one space, replace by one space
    some_txt <- str_replace_all(some_txt, "\\s{2,}", " ") 
    #
    # Remove beginning and ending spaces
    some_txt <-  str_replace_all(some_txt, "^\\s+|\\s+$", "")
    #
    some_txt
}

match_with_negation <- function(phrase, word_table, consider_negation = TRUE,
                                negation_dictionary = c("not", "isn't","aren't", "haven't","won't", "doesn't")){
    #
    # phrase is the phrase being considered
    # word_table is the dictionary of words in which we are looking for matches
    # consider_negation: if TRUE,
    # then the appearance of a negation word before a match is taken into account
    # negation_dictionary is a list of negation words (which we can add to)
    #
    # Obtain the individual words in phrase
    #
    individual_words <- unlist(str_split(phrase, '\\s+')) # Needs package stringr
    #
    # Remove the English articles as these can cause confusion when considering negation
    #
    individual_words <- individual_words[!individual_words %in% c("a", "the")]
    #
    # Where are the matches?
    # Position of the word in the word_table
    # If there is no match NA is reported
    #
    match_positions_in_table <- match(individual_words, word_table)
    #
    # So words that match are those that are not NA
    # Let's record which ones these are
    #
    match_positions_in_phrase <- which(!is.na(match_positions_in_table))
    #
    # How many matches?
    # This is the total number of elements that are not NA
    #
    number_of_matches <- sum(!is.na(match_positions_in_table))
    #
    # If we should take account of the appearance of a negation word before a match:
    #
    if(consider_negation){
        #
        # Position of preceding words
        #
        previous_words_position <- match_positions_in_phrase - 1
        #
        # Make sure that none of these are zero, as we can't index from zero
        #
        previous_words_position <- previous_words_position[previous_words_position > 0]
        #
        # What are those words?
        #
        previous_words <- individual_words[previous_words_position]
        #
        # Do they negate?
        #
        negation_words <- previous_words[previous_words %in% negation_dictionary]
        #
        # Remove the number of negation words from the number of matches
        #
        number_of_matches <- number_of_matches - length(negation_words)
        # So a phrase such as "not good" is recorded as neutral (score 0)
        # rather than 1 for the positive word "good"
    }
    #
    # Return the number of matches
    #
    number_of_matches
}

get.page.data <- function(page_name) {
  

}

token <- "EAACEdEose0cBAF0yytLy7ZBBkcSeuIFTcdsGoYbD69XNYyHdVwuQERJbMRf6o0vgCB6TmZATdGXqbq7ZB14wBtMeH5FSoLD6bhZCbKb7f4ZBK8BEzrCdjVBWDDpz9HZAsStbmKZBvA5AWZCgxPJsPhU7e5N6VI5qrZCvXdpxcANAnAJUsZA5be4vnmeiFXSIwzW4QuIQiDfhckxQZDZD"


```

## Introduction

We chose to do our presentation on the similarities and differences between various game platforms. We chose this as it is something we are familier with, due to us all being games development students, and it could be interesting to look at different variations of the same service.


## Chosen Pages

The three services we will be looking at are:

- Xbox
- Playstation
- Steam

We chose these as they are the most widely used platforms and so were likely to yield the most active FaceBook Pages.

## Xbox and Playstation

These two are both examples of console gaming platforms. They are usually cheaper to get into with a lower barrier of entry. There is a larger focus on major releases periodically throughout the year.

We chose to use two examples of consoles because they are in direct competition so there is the possiblility of analysing similarities and differences between the two.

## Steam

Steam was picked to compare against the two console platforms. It is the primary method for gaming on a PC and therefore tends to have a higher barrier for enrty as a PC can be more expensive up-front than a console. 

Steam also gets the major releases at distinct points throughout the year but has a much greater focus on smaller games releasing very rapidly; almost constantly.

## Playstation

```{r include=FALSE}

page_name <- "PlayStation"
number_required <- 1000
dates <- seq(as.Date("2017/01/31"), as.Date("2018/01/31"), by = "day")
n <- length(dates) - 1
df_daily <- list()

for (i in 1:n){
  cat(as.character(dates[i]), " ")
  try(df_daily[[i]] <- getPage(page_name, token,
                               n = number_required,
                               since = dates[i],
                               until = dates[i + 1],
                               reactions = TRUE,
                               api = "v2.9"))
  cat("\n")
}

my_page <- do.call(rbind, df_daily)

dim(my_page)
names(my_page)
str(my_page)

my_page <- my_page %>%
  mutate(datetime = format.facebook.date(created_time) )

head(my_page$datetime)

my_page <- my_page %>%
  mutate(month = format(datetime, "%Y-%m"))

head(my_page$month)

monthly_summaries_wide <- my_page %>%
  group_by(month) %>%
  summarize("Average likes" = mean(likes_count),
            "Average comments" = mean(comments_count),
            "Average shares" = mean(shares_count),
            #"Average love" = mean(love_count),
            #"Average haha" = mean(haha_count),
            #"Average wow" = mean(wow_count),
            #"Average sad" = mean(sad_count),
            #"Average angry" = mean(angry_count),
            "Number of posts" = n())

monthly_summaries_wide

monthly_summaries <- monthly_summaries_wide %>%
  gather("Monthly_Quantity","Number", 2:5)
monthly_summaries
```

```{r echo=FALSE, warning=FALSE}
ggplot(monthly_summaries, 
       aes(x = month, 
           y = Number, 
           group = Monthly_Quantity, 
           colour = Monthly_Quantity)) +
  geom_line(lwd = 1.5) + 
  facet_wrap(~ Monthly_Quantity, scales = "free_y") + 
  theme(axis.text.x = element_text(size = 14, angle = 270, hjust = 0, vjust = 0.5),
        axis.text.y = element_text(size = 14), 
        axis.title.x = element_text(size = 16),
        axis.title.y = element_text(size = 16, angle = 270),
        strip.text.x = element_text(size = 14),
        title = element_text(size = 20), 
        legend.position = "none") + 
  labs(title = paste(page_name, "Facebook Page"), 
       subtitle = "Monthly Quantity Across Posts",
       x = "Month", 
       y = "Number")
```

## negative/positive playstation

```{r, include=FALSE}
my_page$message
my_page_existing_messages <- my_page %>% 
  filter(!is.na(message))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = remove_http_www(message))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = str_replace_all(message_cleaned, "[^[:alnum:]]",  " ") )
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = str_replace_all(message_cleaned, "[\u4E00-\u9FFF]+",  " ") )
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = str_replace_all(message_cleaned, "[\u3400-\u4DBF]+",  " ") )
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = remove.numbers(message_cleaned))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = remove.spaces(message_cleaned))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned =  tolower(message_cleaned))
my_page_existing_messages$message_cleaned

#Word Counts/Frequency
text_corpus <- Corpus(VectorSource(my_page_existing_messages$message_cleaned))
text_corpus

new.stopwords <- c("http", "https", "ps4", "playstation", "sony")

tdm <- TermDocumentMatrix(text_corpus, 
                          control = list(stopwords = c(new.stopwords, 
                                                       stopwords(kind = "en"))))
tdm_matrix <- as.matrix(tdm)
dim(tdm_matrix)
tdm_matrix[1:25, 1:25]
word_count <- rowSums(tdm_matrix)
head(word_count)
word_count_df <- data.frame(word = names(word_count), freq = word_count)
word_count_ordered_df <- word_count_df %>% 
  arrange(desc(freq))
head(word_count_ordered_df)

N <- 8
words_freq_limited <- word_count_ordered_df[1:N,]
words_freq_limited <- words_freq_limited %>% 
  mutate(word = factor(word, levels = word))
words_freq_limited$word
```

```{r, echo=FALSE}

g_w_b <- rep(c("darkblue", "white", "black"), length = N)
ggplot(words_freq_limited, 
       aes(x = word, 
           y = freq)) +
  geom_col(fill = g_w_b, colour = "black", alpha = 0.9) + 
  # colour refers to the edge of the bars        
  # values of alpha less than 1 cause transparency
  labs(title = paste("Most Common Words - ", page_name),
       x = paste("Top", N, "Words"), 
       y = "Frequency") + 
  theme(axis.text = element_text(size = 14, color = "black"), 
        axis.title = element_text(size = 18, color = "black"),
        title = element_text(size = 20))
     
```


## Steam

```{r, include=FALSE}
page_name <- "Steam"

number_required <- 1000 

dateToUse <- "2018/01/31"

dates <- seq(as.Date("2017/01/31"), as.Date(dateToUse), by = "day")
dates

n <- length(dates) - 1
n

df_daily <- list()

for (i in 1:n){
  
  cat(as.character(dates[i]), " ") 
  
  try(df_daily[[i]] <- getPage(page_name, token, 
                               n = number_required, 
                               since = dates[i], 
                               until = dates[i + 1], 
                               reactions = TRUE,
                               api = "v2.9")) 
  
  cat("\n")
}

my_page <- do.call(rbind, df_daily)

my_page <- my_page %>% 
  mutate(datetime = format.facebook.date(created_time) )

head(my_page$datetime)

my_page <- my_page %>% 
  mutate(month = format(datetime, "%Y-%m"))

monthly_summaries_wide <- my_page %>%
  group_by(month) %>%
  summarize("Average likes" = mean(likes_count),
            "Average comments" = mean(comments_count),
            "Average shares" = mean(shares_count),
            #"Average love" = mean(love_count),
            #"Average haha" = mean(haha_count),
            #"Average wow" = mean(wow_count),
            #"Average sad" = mean(sad_count), 
            #"Average angry" = mean(angry_count),
            "Number of posts" = n())

monthly_summaries <- monthly_summaries_wide %>% 
  gather("Monthly_Quantity","Number", 2:5) 
```

```{r, echo=FALSE}
ggplot(monthly_summaries, 
       aes(x = month, 
           y = Number, 
           group = Monthly_Quantity, 
           colour = Monthly_Quantity)) +
  geom_line(lwd = 1.5) + # Specify line width 
  facet_wrap(~ Monthly_Quantity, scales = "free_y") + # Use a free scale on the y-axis
  theme(axis.text.x = element_text(size = 14, angle = 270, hjust = 0, vjust = 0.5), # For rotated labels
        axis.text.y = element_text(size = 14), 
        axis.title.x = element_text(size = 16),
        axis.title.y = element_text(size = 16, angle = 270),
        strip.text.x = element_text(size = 14),
        title = element_text(size = 20), 
        legend.position = "none") + 
  labs(title = paste(page_name, "Facebook Page"), # Note the use of paste to create a title of the page name followed by some text (see below)
       subtitle = "Monthly Quantity Across Posts",
       x = "Month", 
       y = "Number") 

```

## Negative/positive steam

```{r, include=FALSE}
my_page$message
my_page_existing_messages <- my_page %>% 
  filter(!is.na(message))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = remove_http_www(message))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = str_replace_all(message_cleaned, "[^[:alnum:]]",  " ") )
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = str_replace_all(message_cleaned, "[\u4E00-\u9FFF]+",  " ") )
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = str_replace_all(message_cleaned, "[\u3400-\u4DBF]+",  " ") )
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = remove.numbers(message_cleaned))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = remove.spaces(message_cleaned))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned =  tolower(message_cleaned))
my_page_existing_messages$message_cleaned

#Word Counts/Frequency
text_corpus <- Corpus(VectorSource(my_page_existing_messages$message_cleaned))
text_corpus

new.stopwords <- c("http", "https", "steam", "valve", "pc")

tdm <- TermDocumentMatrix(text_corpus, 
                          control = list(stopwords = c(new.stopwords, 
                                                       stopwords(kind = "en"))))
tdm_matrix <- as.matrix(tdm)
dim(tdm_matrix)
tdm_matrix[1:25, 1:25]
word_count <- rowSums(tdm_matrix)
head(word_count)
word_count_df <- data.frame(word = names(word_count), freq = word_count)
word_count_ordered_df <- word_count_df %>% 
  arrange(desc(freq))
head(word_count_ordered_df)

N <- 8
words_freq_limited <- word_count_ordered_df[1:N,]
words_freq_limited <- words_freq_limited %>% 
  mutate(word = factor(word, levels = word))
words_freq_limited$word
```


```{r, echo=FALSE}
bg <- rep(c("gray0", "gray25", "gray50"), length = N)
ggplot(words_freq_limited, 
       aes(x = word, 
           y = freq)) +
  geom_col(fill = bg, colour = "black", alpha = 0.9) + 
  # colour refers to the edge of the bars        
  # values of alpha less than 1 cause transparency
  labs(title = paste("Most common words in post to page", page_name),
       x = paste("Top", N, "Words"), 
       y = "Frequency") + 
  theme(axis.text = element_text(size = 13, color = "black"), 
        axis.title = element_text(size = 18, color = "black"),
        title = element_text(size = 20))
```


##Xbox

```{r, include=FALSE}
page_name <- "xbox"
number_required <- 1000
Sys.Date()
dates <- seq(as.Date("2017/01/31"), as.Date("2018/01/31"), by = "day")
n <- length(dates) - 1
df_daily <- list()
#
for (i in 1:n){
  cat(as.character(dates[i]), " ") 
  try(df_daily[[i]] <- getPage(page_name, token, 
                               n = number_required, 
                               since = dates[i], 
                               until = dates[i + 1], 
                               reactions = TRUE,
                               api = "v2.9"))
  cat("\n")
}
#
my_page <- do.call(rbind, df_daily)
# Facebook Stats

my_page <- my_page %>% 
  mutate(datetime = format.facebook.date(created_time) )
head(my_page$datetime)
my_page <- my_page %>% 
  mutate(month = format(datetime, "%Y-%m"))
head(my_page$month)
monthly_summaries_wide <- my_page %>%
  group_by(month) %>%
  summarize("Average likes" = mean(likes_count),
            "Average comments" = mean(comments_count),
            "Average shares" = mean(shares_count),
            #"Average love" = mean(love_count),
            #"Average haha" = mean(haha_count),
            #"Average wow" = mean(wow_count),
            #"Average sad" = mean(sad_count), 
            #"Average angry" = mean(angry_count),
            "Number of posts" = n())
monthly_summaries_wide 
monthly_summaries <- monthly_summaries_wide %>% 
  gather("Monthly_Quantity","Number", 2:5) 
monthly_summaries
```

```{r}
ggplot(monthly_summaries, 
       aes(x = month, 
           y = Number, 
           group = Monthly_Quantity, 
           colour = Monthly_Quantity)) +
  geom_line(lwd = 1.5) + # Specify line width 
  facet_wrap(~ Monthly_Quantity, scales = "free_y") + 
  theme(axis.text.x = element_text(size = 14, angle = 270, hjust = 0, vjust = 0.5), 
        axis.text.y = element_text(size = 14), 
        axis.title.x = element_text(size = 16),
        axis.title.y = element_text(size = 16, angle = 270),
        strip.text.x = element_text(size = 14),
        title = element_text(size = 20), 
        legend.position = "none") + 
  labs(title = paste(page_name, "Facebook Page"), 
       subtitle = "Monthly Quantity Across Posts",
       x = "Month", 
       y = "Number") 
```

## negative/positive xbox

```{r, include=FALSE}
my_page_existing_messages <- my_page %>% 
  filter(!is.na(message))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = remove_http_www(message))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = str_replace_all(message_cleaned, "[^[:alnum:]]",  " ") )
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = str_replace_all(message_cleaned, "[\u4E00-\u9FFF]+",  " ") )
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = str_replace_all(message_cleaned, "[\u3400-\u4DBF]+",  " ") )
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = remove.numbers(message_cleaned))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned = remove.spaces(message_cleaned))
my_page_existing_messages <- my_page_existing_messages %>% 
  mutate(message_cleaned =  tolower(message_cleaned))
text_corpus <- Corpus(VectorSource(my_page_existing_messages$message_cleaned))
new.stopwords <- c("http", "https", "youtube", "xbox", "microsoft") 
tdm <- TermDocumentMatrix(text_corpus, 
                          control = list(stopwords = c(new.stopwords, 
                                                       stopwords(kind = "en"))))
tdm_matrix <- as.matrix(tdm)
tdm_matrix[1:25, 1:25]
word_count <- rowSums(tdm_matrix)
head(word_count)
word_count_df <- data.frame(word = names(word_count), freq = word_count)
word_count_ordered_df <- word_count_df %>% 
  arrange(desc(freq))
head(word_count_ordered_df)
N <- 8
words_freq_limited <- word_count_ordered_df[1:N,]
words_freq_limited <- words_freq_limited %>% 
  mutate(word = factor(word, levels = word))
words_freq_limited$word

```

```{r}
#plots
#-----------------------------
#
col <- rep(c("limegreen", "white"), length = N)

ggplot(words_freq_limited, 
       aes(x = word, 
           y = freq)) +
  geom_col(fill = col) + 
  labs(title = paste("Most common words in post to page", page_name),
       x = paste("Top", N, "Words"), 
       y = "Frequency") + 
  theme(axis.text = element_text(size = 13, color = "black"), 
        axis.title = element_text(size = 18, color = "black"),
        title = element_text(size = 20))
```


## Number of comments over a year (all 3)

## Likes over a year









## Mood of responses in all three